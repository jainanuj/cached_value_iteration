/* track.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>
#include "solve.h"
#include "graph.h"
#include "lao.h"
#include "vi.h"
#include "backup.h"

/* The racetrack input file is generated by a pearl script called
   build.pl which is run on a map of the track.

   Format for racetrack input file:
     first line: 
         total number of states
	 discount factor
     second line: 
         list of start states (equal probability of starting in each)
     subsequent lines: 
         state index
	 state description
	 action index
	 0 if regular state, 1 if GOAL, 2 if WALL
	 (goal probability -- not used, is 1.0 for GOAL, otherwise 0.0)
	 next state if action succeeeds
	 next state if action fails

   After generating input file using pearl script, make the following
   changes: 
    -- add the first two lines
    -- change terminal value for WALL from 1 to 2 so that the wall 
       can be distinguished from the goal state.

   Note that hitting the wall causes a transition to a start state.

   The start state (-1) and wall state have zero cost transition to
   uniform probability distribution over possible start states.
*/

void readRacetrackMDP (void)
{
  FILE*                     file;
  char                      description[15];
  char                      str[30]; /* for reading lines of input file */
  int                       state, action, nextStateSuccess, nextStateFail,
                            numFields, terminal, start[6], i;
  float                     goalProb;
  struct StateNode*         stateNode;
  struct ActionNode*        actionNode;
  struct ActionListNode*    actionList;
  struct StateDistribution* Distribution;

  file = fopen(gInputFileName, "r");
  if ( file == NULL) {
    printf("Data file %s not found!\n", gInputFileName);
    exit(1);
  }

  fgets(str, 100, file); 
  sscanf(str, "%d %lf", &gNumStates, &gDiscount); 
  gNumActions = 9; /* racetrack problem has 9 actions */

  /* allocate vector of state nodes */
  StateIndex = 
    (struct StateNode**)malloc((unsigned)gNumStates*sizeof(struct StateNode*));
  for (state = 0; state < gNumStates; state++) {
    StateIndex[state] = CreateStateNode();
    StateIndex[state]->StateNo = state;
    /* also allocate memory for state description */
    StateIndex[state]->Description = (char*)malloc(15*sizeof(char));
    /* set initial action lists to NULL */
    StateIndex[state]->Action = NULL;
    StateIndex[state]->PrevAction = NULL;
    StateIndex[state]->BestPrevAction = NULL;
    /* Initial heuristic cost-to-go is zero */
    StateIndex[state]->f = 0.0;
  }

  /* build start state */
  fgets(str, 100, file); 
  numFields = sscanf(str, "%d %d %d %d %d %d",
	   &start[0], &start[1], &start[2], &start[3], &start[4], &start[5]);
  Start = CreateStateNode();
  Start->StateNo = -1;
  Start->Description = "START";
  Start->f = 0.0;
  //Start->Terminal = 0;
  Start->Terminal = 3;	/* for special use only */
  Start->Expanded = 0;
  Start->Action = CreateActionList();
  Start->Action->Next = NULL;
  Start->Action->Node = Start->BestAction = CreateActionNode();
  Start->Action->Node->ActionNo = -1;
  Start->Action->Node->Cost = 0.0;
  Start->Action->Node->PrevState = Start;
  Start->Action->Node->NextState = CreateStateDistribution();
  Distribution = Start->Action->Node->NextState;
  Distribution->State = StateIndex[start[0]];
  Distribution->Prob = 1.0/numFields;
  StateIndex[start[0]]->PrevAction = CreateActionList();
  AppendActionList(StateIndex[start[0]]->PrevAction, Start->BestAction);
  StateIndex[start[0]]->BestPrevAction = Start->BestAction;
  for (i = 1; i < numFields; i++) {
    Distribution->Next = CreateStateDistribution();
    Distribution = Distribution->Next;
    Distribution->State = StateIndex[start[i]];
    Distribution->Prob = 1.0/numFields;
    StateIndex[start[i]]->PrevAction = CreateActionList();
    AppendActionList(StateIndex[start[i]]->PrevAction, Start->BestAction);
    StateIndex[start[i]]->BestPrevAction = Start->BestAction;
  }
  Distribution->Next = NULL;
  
  /* each input line begins with state number and contains 
     transition probs for a state-action pair */
  while (!feof(file)) {
    fgets(str, 100, file); 
    numFields = sscanf(str, "%d %s %d %d %f %d %d",
	   &state,
	   description,
	   &action,
	   &terminal,
	   &goalProb,
	   &nextStateSuccess,
	   &nextStateFail);
    stateNode = StateIndex[state];
    strncpy(stateNode->Description, description, 15);
    stateNode->Terminal = terminal;

    /* Only non-terminal states have next states. In a non-terminal 
       state, every action has two next states and a cost of 1.0. */
    if (stateNode->Terminal == 0) {

      /* allocate memory for action and add to list of actions */
      actionList = CreateActionList();
      actionNode = CreateActionNode();
      actionNode->ActionNo = action;
      actionList->Node = actionNode;
      /* insert new action node at beginning of list */
      actionList->Next = stateNode->Action;
      stateNode->Action = actionList;
      /* create best action is it doesn't already exist */
      if (!stateNode->BestAction) 
	stateNode->BestAction = actionNode;
      /* create best prev action here */
      /*  */

      /* Update PrevAction of the first successor state */
      /* Allocate memory for next state distributions */
      actionNode->NextState = CreateStateDistribution();
      actionNode->NextState->State = StateIndex[nextStateSuccess];
      /* Also add pointers from next states back to this action. */
      actionList = CreateActionList();
      actionList->Node = actionNode;
      actionList->Next = StateIndex[nextStateSuccess]->PrevAction;
      StateIndex[nextStateSuccess]->PrevAction = actionList;
      StateIndex[nextStateSuccess]->BestPrevAction = actionNode;
      if (numFields == 7) { /* 2 possible next states */
	/* actions have intended effect with probability 0.9 */
	actionNode->NextState->Prob = 0.9;
	actionNode->NextState->Next = CreateStateDistribution();
	actionNode->NextState->Next->State = StateIndex[nextStateFail];
	actionNode->NextState->Next->Prob = 0.1;
	actionNode->NextState->Next->Next = NULL;
	/* Also add pointer from next states back to this action. */
	actionList = CreateActionList();
	actionList->Node = actionNode;
	actionList->Next = StateIndex[nextStateFail]->PrevAction;
	StateIndex[nextStateFail]->PrevAction = actionList;
        StateIndex[nextStateFail]->BestPrevAction = actionNode;
	Start->BestPrevAction = actionNode;
      }
      else { /* 1 possible next state */
	actionNode->NextState->Prob = 1.0;
	actionNode->NextState->Next = NULL;
      }
      /* cost of every action is 1.0 */
      actionNode->Cost = 1.0;
      /* pointer to state in which action is taken */
      actionNode->PrevState = stateNode;
    }
    else if (stateNode->Terminal == 1) {
      stateNode->f = 0.0;
      Goal = stateNode;
    }
    else if (stateNode->Terminal == 2) { /* wall */
      stateNode->f = 0.0;
      stateNode->Action = CreateActionList();
      stateNode->Action->Next = NULL;
      stateNode->Action->Node = stateNode->BestAction = CreateActionNode();
      stateNode->Action->Node->ActionNo = -1;
      stateNode->Action->Node->Cost = 0.0;
      stateNode->Action->Node->PrevState = stateNode;
      stateNode->Action->Node->NextState = 
	Start->Action->Node->NextState;
      /* make WALL parent of START */
      actionList = CreateActionList();
      actionList->Node = stateNode->Action->Node;
      actionList->Next = Start->PrevAction;
      Start->PrevAction = actionList;
    }
  }
  fclose(file);
}

void CreateHeuristic(void)
/****** This doesn't yet work correctly for discounted MDPs ******/
{
  struct StateListNode *CurrentList, *NewList, *node;
  struct ActionListNode *prev;

  CurrentList = CreateStateList();

  /* Initial CurrentList contains GOAL */
  Goal->h = 0.0;
  Goal->g = 0.0;
  Goal->f = 0.0;
  Goal->fWeight = 0.0;
  AppendStateList(CurrentList, Goal);

  /* Add unvisited states that can be reached by one backward step */
  while (CurrentList->Node) { /* check for empty list */
    NewList = CreateStateList();
    /* For each state added in previous step ... */
    for (node = CurrentList; node; node = node->Next) {
      /* ... and for each parent of that state ... */
      for (prev = node->Node->PrevAction; prev; prev = prev->Next) {
	/* If parent has not already been updated, update heuristic and 
	   add to list */
	if (prev->Node->PrevState->h == 0.0) {
	  prev->Node->PrevState->f =
	    prev->Node->PrevState->h = 
	                         gDiscount * node->Node->h + prev->Node->Cost;
	  prev->Node->PrevState->g = 0.0;
	  prev->Node->PrevState->fWeight = gWeight * prev->Node->PrevState->f;
	  AppendStateList(NewList, prev->Node->PrevState);
	}
      }
    }
    DeleteStateList(CurrentList);
    CurrentList = NewList;
    NewList = NULL;
  }
  DeleteStateList(CurrentList);
}

void initMeanFirstPassage (void)
{
  int state;

  for (state = 0; state < gNumStates; state++)
    if (StateIndex[state]->Terminal == 1)
      StateIndex[state]->meanFirstPassage = 0.0;
    else
      StateIndex[state]->meanFirstPassage = 200.0;
}
